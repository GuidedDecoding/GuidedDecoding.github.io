<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Self-Evaluation Guided Beam Search for Reasoning">
  <meta name="keywords" content="Large Language Models (LLM) Reasoning, LLM Self-Evaluation, Decoding Strategy">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Guided-Decoding</title>

  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.0/es5/tex-mml-chtml.js">
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">
  <link rel="icon" href="./static/images/layout.png">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Self-Evaluation Guided</h1>
          <h1 class="title is-1 publication-title">Beam Search for Reasoning</h1>
          <h1 class="title is-2 publication-title">(NeurIPS 2023)</h1>
          <!-- <h1 class="title is-2 publication-title" style="margin-top: -17px;">for Text-to-Image Generation</h1> -->
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuxixie.github.io/">Yuxi Xie</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://ml.comp.nus.edu.sg/kawaguchi">Kenji Kawaguchi</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=D_HwSlEAAAAJ&hl=en">Yiran Zhao</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Ybcwc2IAAAAJ&hl=en">James Xu Zhao</a><sup>1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.comp.nus.edu.sg/~kanmy/">Min-Yen Kan</a><sup>1#</sup>,</span>
            <span class="author-block">
              <a href="https://jxhe.github.io/">Junxian He</a><sup>2#</sup>,</span>
            <span class="author-block">
              <a href="https://www.michaelxie.com/">Michael Qizhe Xie</a><sup>1#</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b>1. National University of Singapore</span>
            <br>
            <span class="author-block"><b style="color:#00A4EF; font-weight:normal">&#x25B6 </b>2. Hong Kong University of Science and Technology</span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block" style="font-size: 15px;"><sup>*</sup>Correspondence</span> &nbsp; &nbsp; &nbsp; &nbsp;
            <span class="author-block" style="font-size: 15px;"><sup>#</sup>Equal Advising</span>
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2305.00633"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/YuxiXie/SelfEval-Guided-Decoding"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img class="columns is-centered has-text-centered" src="./static/images/running-exp.jpg" alt="Teaser" width="100%" style="margin:0 auto">
      <!-- <iframe class="columns is-centered has-text-centered" src="./static/images/running-exp.pdf" type="application/pdf" alt="Teaser" width="100%" height="600px" style="margin:0 auto"></iframe> -->
      <h2 class="subtitle">
        <br/>
        <p>
          We propose <span style="color: rgb(50, 154, 50)"><b>Self-Evaluation Guided Beam Search</b></span>, a framework of stepwise LLM reasoning.
        </p>
        <p>
          Self-Evaluation can calibrate the decoding direction step by step in reasoning. 
          We illustrate our method with the beam size equal to 1. 
          The scale of the self-evaluation score is visualized in the colormap.
        </p>

      </h2>

    </div>
    
  </div>

</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a stepwise self-evaluation mechanism tailored to enhance the reasoning capabilities of Large Language Models (LLMs). 
            We propose an effective prompting framework integrating self-evaluation guidance via stochastic beam search. 
            The self-evaluation guidance serves as a better-calibrated automatic criterion, facilitating an efficient search in the reasoning space and resulting in superior prediction quality. 
            With temperature-controlled randomness, stochastic beam search balances exploitation and exploration of the reasoning search space. 
            This allows our approach to excel in producing high-quality single-chain generation and adapt well to the multiple-chain scenario with high diversity. 
            Our approach surpasses the corresponding Codex-backboned baselines in few-shot accuracy by 6.34%, 9.56%, and 5.46% on the GSM8K, AQuA, and StrategyQA benchmarks, respectively. 
            Further analysis in multi-step reasoning finds our self-evaluation guidance pinpoints logic failures and leads to higher consistency and robustness.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">Self-Evaluation Guided Stochastic Beam Search</h2>
      <div class="content has-text-justified">
        <p>
          Prior works on LLM reasoning illustrate significant improvement in model performance by <span style="color: rgb(50, 154, 50)">breaking down a problem into intermediate stages</span> &ndash; a reasoning chain (e.g., <a href="https://arxiv.org/abs/2201.11903"><em>chain-of-thought</em></a> (CoT), <a href="https://arxiv.org/abs/2211.10435"><em>program-aided language models</em></a> (PAL)). 
          However, as the complexity and length of reasoning chains increase, LLMs struggle with errors and imperfections that accumulate across multiple intermediate steps. Furthermore, the growing number of steps leads to an <span style="color: rgb(50, 154, 50)">exponential growth in the search space for reasoning</span>, making it exceedingly difficult to obtain accurate final outcomes.
        </p>
        <p>
          In our work, we introduce a <span style="color: rgb(50, 154, 50)">stepwise self-evaluation</span> mechanism tailored to facilitate an efficient search in the reasoning space.
          We adopt LLM <em>self-evaluation</em> as an automatic criterion to guide the reasoning process, drawing inspiration from previous works on utilizing LLMs for self-evalution (<a href="https://arxiv.org/abs/2207.05221">Kadavath et al. 2023</a>).
          Specifically, we formulate the reasoning chain generation as a decoding process consisting of multiple intermediate steps. 
          We employ <span style="color: rgb(50, 154, 50)">stochastic beam search decoding</span> to balance the exploitation and exploration of the reasoning search space with temperature-controlled randomness.
        </p>

      </div>

    </div>

  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop is-centered has-text-centered">
      <h2 class="title is-3">Generated Examples</h2>
      <div class="content has-text-justified">
        <br/>
        <p>
          We compare the predictions of baseline and our methods on particular instances.
          Scores from low to high are visualized from <span style="background-color: rgb(255, 188, 103)">orange</span>, <span style="background-color: rgb(254, 252, 186)">yellow</span>, to <span style="background-color: rgb(145, 211, 103)">green</span>. Here \(\mathcal{C}\), \(\mathcal{P}\), and \(\mathcal{E}\) represent the evaluation confidence, the generation confidence (probability), and their combination as the final self-evaluation score, respectively.
        </p>
        <p>
          In general, the evaluation confidence \(\mathcal{C}\) is more effective at identifying logical errors, taking into account accumulated mistakes from prior steps, while the generation probability \(\mathcal{P}\) focuses more on text perplexity as the confidence of the LLM generator.
        </p>

      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4">Arithmetic Reasoning</h2>
          <img src="./static/images/gsm8k-pal.jpg" alt="Teaser" width="100%">
          <img src="./static/images/gsm8k-cot.jpg" alt="Teaser" width="100%">

        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full-width">
          <h2 class="title is-4">Commonsense Reasoning</h2>
          <img src="./static/images/sqa-cot.jpg" alt="Teaser" width="100%">
  
        </div>
      </div>

    </div>
    
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            You may refer to related works such as <a href="https://arxiv.org/abs/2201.11903">CoT</a>, 
            <a href="https://arxiv.org/abs/2211.10435">PAL</a>, 
            <a href="https://arxiv.org/abs/2305.08291">Tree-of-Thought</a>, 
            and <a href="https://www.llm-reasoners.net/">LLM-Reasoners</a> 
            which serve as foundations and variations of our Guided-Decoding framework and code repository.
          </p>
        </div>
      </div>
    </div>

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{xie2023decomposition,
      title={Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding}, 
      author={Yuxi Xie and Kenji Kawaguchi and Yiran Zhao and Xu Zhao and Min-Yen Kan and Junxian He and Qizhe Xie},
      year={2023},
      eprint={2305.00633},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align: center;">
            The webpage is built based on <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
